\documentclass[12pt,a4paper]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{float}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{algorithm}
\usepackage{algpseudocode}

% Adjust formatting
\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\onehalfspacing
\usepackage{times}

% Define colors for code
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

% Listing style for code
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}

\title{DFN-PSAN: Multi-level deep information feature fusion extraction network for interpretable plant disease classification}
\author{Your Name}
\date{}

\begin{document}

\maketitle

\section{Introduction}
\textbf{Keywords:} Deep learning, Image processing, Feature fusion, Multilevel features, Pixel attention, Disease classification

Accurate identification of crop diseases is an effective way to promote the development of intelligent and modernized agricultural production, as well as to reduce the use of pesticides and improve crop yield and quality. Deep learning methods have achieved better performance in classifying input plant disease images. However, many plant disease datasets are often constructed from controlled scenarios, and these deep learning models may not perform well when tested in real-world agricultural environments, highlighting the challenges of transitioning to natural farm environments under the new demand paradigm of Agri 4.0.

Based on the above reasons, this work proposes using a multi-level deep information feature fusion extraction network (DFN-PSAN) to achieve plant disease classification in natural field environments. DFN-PSAN adopts the YOLOv5 Backbone and Neck network as the base structure DFN and uses pyramidal squeezed attention (PSA) combined with multiple convolutional layers to design a novel classification network PSAN, which fuses and processes the multi-level depth information features output from DFN and highlights the critical regions of plant disease images with the help of pixel-level attention provided by PSA, thus realizing effective classification of multiple fine-grained plant diseases.

The proposed DFN-PSAN was trained and tested on three plant disease datasets. The average accuracy and F1-score exceeded 95.27\%. The PSA attention mechanism saved 26\% of model parameters, achieving a competitive performance among existing related methods. In addition, this work effectively enhances the transparency and interpretability of the model.

\section{Motivation}
Agriculture is a cornerstone of national development, playing a critical role in the economy and food security. The following facts underscore the importance and urgency of improving crop disease identification:

\begin{itemize}
  \item According to the Food and Agriculture Organization (FAO), agricultural productivity is essential for ensuring food security for a growing global population.
  \item Crop diseases can reduce yields by up to 30\% annually, leading to substantial economic losses for farmers (Jayagopal et al., 2022).
  \item Traditional methods of disease identification, such as manual inspection, are time-consuming and often ineffective, resulting in delayed responses to disease outbreaks.
  \item Early and accurate detection of diseases can significantly mitigate yield losses and improve the quality of crops, thus enhancing overall food security (Legrand, 2023).
  \item The rise of advanced technologies, such as machine learning and computer vision, offers new opportunities to transform crop disease detection by providing rapid, precise, and scalable solutions.
\end{itemize}

By leveraging these technologies, this project aims to address the limitations of traditional methods, enabling more efficient disease identification and timely interventions. This approach promises to safeguard agricultural production, reduce economic impacts, and support national food security.

\section{Novel Lightweight Deep Learning Model}
Based on the YOLOv5 network, we designed a novel lightweight deep learning model to identify plant diseases. The model, named DFN-PSAN, improves upon the original YOLOv5 network by:

\begin{itemize}
  \item Keeping the feature extraction network (Backbone) and the feature fusion network (Neck)
  \item Removing the Head structure
  \item Designing a novel PSAN classification network structure for plant disease classification
  \item Implementing Pyramid Squeeze Attention (PSA) for PSAN, allowing the network to focus on important features and ignore unimportant ones
\end{itemize}

\section{Main Contributions}
\begin{itemize}
  \item The DFN structure obtains information on plant disease characteristics at different scales through image feature fusion techniques.
  \item The PSAN structure utilizes rich information on important semantic features, with the embedded PSA attention mechanism reinforcing important information and suppressing non-important information.
  \item A two-stage weather data augmentation technique is used for plant disease datasets in three real agricultural scenarios, improving model generalization and suppressing overfitting.
  \item The t-SNE method is used to interpret the feature layer data of the DFN-PSAN model through visualization of two-dimensional clustering distribution.
  \item The SHAP interpretable AI (XAI) visualization method explains whether DFN-PSAN correctly focuses on plant disease features or pattern information.
\end{itemize}

% Continue with other sections...

\section{Technical Details}
\begin{itemize}
  \item Image processing: VS code and Python 3.10
  \item Deep learning framework: PyTorch 1.13.1 + cu117
  \item Image processing library: OpenCV
  \item Hardware acceleration: GPU
\end{itemize}

\section{DFN-PSAN Architecture with PSA}
The DFN-PSAN (Deep Fusion Network with Pyramid Squeeze Attention Network) architecture is an improvement of YOLOv5, designed for more accurate plant disease detection. It focuses on enhanced feature extraction and classification through the use of Pyramid Squeeze Attention (PSA), which boosts the model's ability to focus on important features in plant images.

\subsection{Key Components}
\subsubsection{YOLOv5 for Feature Extraction}
YOLOv5, a real-time object detection model, handles feature extraction. While YOLOv5n offers speed and low weight, it lacks deep feature extraction capability. To address this, DFN-PSAN introduces modifications to improve feature extraction, fusion, and convergence speed.

\subsubsection{YOLOv5 Architecture}
\textbf{Backbone:} Utilizes CSPDarkNet with a 6 Ã— 6 convolutional layer replacing the older Focus structure.

\textbf{SPP Module:} Expands the receptive field, extracting both local and global features through max-pooling at various scales. The operation can be represented as:

\begin{equation}
SPP(FM) = Concat(MaxPool(FM,k_1), MaxPool(FM,k_2), MaxPool(FM,k_3))
\end{equation}

where $FM$ is the input feature map and $k_i$ are the pooling kernel sizes.

\subsubsection{Neck (DFN)}
The Neck combines the Feature Pyramid Network (FPN) and Path Aggregation Network (PAN). The FPN upscales feature maps from lower levels to capture high-level semantic information, while the PAN downscales feature maps from higher levels to improve localization accuracy. This can be described mathematically as:

\begin{equation}
FPN(x) = Upsample(x) + SkipConnection(x)
\end{equation}
\begin{equation}
PAN(x) = Downsample(x) + SkipConnection(x)
\end{equation}

where $x$ represents the feature maps at various levels of the network.

\subsubsection{PSAN Classification Layer}
The PSAN classification layer replaces YOLOv5's Head to enhance classification performance. The Pyramid Squeeze Attention mechanism refines the focus on important features using:

\begin{equation}
PSA(FM) = GAP(Attention(FM))
\end{equation}

where $GAP$ represents Global Average Pooling and $Attention$ denotes the attention mechanism applied to the feature map $FM$.

\subsubsection{Feature Fusion and Attention}
The Neck structure integrates features from various layers, improving the network's ability to handle objects at different scales. The attention mechanism, which can be expressed as:

\begin{equation}
Attention(FM) = \sigma(W \cdot FM + b)
\end{equation}

where $\sigma$ is the activation function, $W$ is the weight matrix, and $b$ is the bias, enhances the focus on relevant features. Classification is performed using the Softmax function:

\begin{equation}
Softmax(x_i) = \frac{e^{x_i}}{\sum_j e^{x_j}}
\end{equation}

which converts the output logits into probabilities for each class.

\subsubsection{Training}
Training involves updating the model parameters using a deep neural network with 30 hyperparameters. The optimization process minimizes the cross-entropy loss function with label smoothing, which can be expressed as:

\begin{equation}
Loss = -\sum_{i=1}^N y_i \log(p_i)
\end{equation}

where $N$ is the total number of categories, $y_i$ is the prediction result for category $i$, $p_i$ is the confidence score of the network output for category $i$, and $\epsilon$ is the label smoothing hyperparameter. Label smoothing modifies $y_i$ as follows:

\begin{equation}
y_i = 
\begin{cases} 
1 - \epsilon & \text{if } i \text{ is the target category} \\
\frac{\epsilon}{N} & \text{if } i \text{ is not the target category}
\end{cases}
\end{equation}

The loss function with label smoothing helps improve the model's generalization by preventing it from becoming too confident about its predictions.

\subsection{Data Preprocessing}
Data preprocessing is divided into two main stages:

\subsubsection{Preliminary basic image preprocessing}
\begin{itemize}
    \item Image read-in and format conversion
    \item Adaptive scaling
    \item Gaussian filtering
    \item Non-local mean noise reduction
    \item Brightness and contrast adjustment
\end{itemize}

\subsubsection{Weather Data Augmentation}
\begin{itemize}
    \item Solar illumination transformation
    \item Raindrop transformation
    \item Shadow transformation
    \item Fog transformation
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{placeholder_image.png}
\caption{Effect of two-stage image processing on image quality}
\label{fig:image_processing}
\end{figure}


\section{Approach to Implementation}

To approach writing code for this research paper, we'll break down the problem into manageable steps:

\subsection{1. Understand the architecture}
\begin{itemize}
    \item YOLOv5 as the backbone and neck (DFN)
    \item Custom classification network (PSAN) with pyramidal squeezed attention (PSA)
    \item Multi-level feature fusion
\end{itemize}

\subsection{2. Set up the environment}
\begin{itemize}
    \item Choose PyTorch as the deep learning framework
    \item Set up necessary libraries (PyTorch, numpy, etc.)
\end{itemize}

\begin{lstlisting}[language=Python, caption=Environment Setup]
import torch
import torch.nn as nn
import numpy as np
import cv2
from torchvision import transforms
\end{lstlisting}

\subsection{3. Implement the components}
\subsubsection{a. YOLOv5 backbone and neck (DFN)}
\begin{lstlisting}[language=Python, caption=YOLOv5 Backbone and Neck]
class YOLOv5Backbone(nn.Module):
    def __init__(self):
        super(YOLOv5Backbone, self).__init__()
        # Implement YOLOv5 backbone layers
        # ...

class YOLOv5Neck(nn.Module):
    def __init__(self):
        super(YOLOv5Neck, self).__init__()
        # Implement YOLOv5 neck layers
        # ...
\end{lstlisting}

\subsubsection{b. Pyramidal Squeezed Attention (PSA) module}
\begin{lstlisting}[language=Python, caption=Pyramidal Squeezed Attention]
class PSA(nn.Module):
    def __init__(self, channels):
        super(PSA, self).__init__()
        # Implement PSA layers
        # ...

    def forward(self, x):
        # Implement PSA forward pass
        # ...
        return x
\end{lstlisting}

\subsubsection{c. Classification network (PSAN)}
\begin{lstlisting}[language=Python, caption=Classification Network (PSAN)]
class PSAN(nn.Module):
    def __init__(self, num_classes):
        super(PSAN, self).__init__()
        # Implement PSAN layers
        # ...

    def forward(self, x):
        # Implement PSAN forward pass
        # ...
        return x
\end{lstlisting}

\subsubsection{d. Multi-level feature fusion mechanism}
\begin{lstlisting}[language=Python, caption=Multi-level Feature Fusion]
class FeatureFusion(nn.Module):
    def __init__(self):
        super(FeatureFusion, self).__init__()
        # Implement feature fusion layers
        # ...

    def forward(self, features):
        # Implement feature fusion forward pass
        # ...
        return fused_features
\end{lstlisting}

\subsection{4. Combine the components to create the DFN-PSAN model}
\begin{lstlisting}[language=Python, caption=DFN-PSAN Model]
class DFNPSAN(nn.Module):
    def __init__(self, num_classes):
        super(DFNPSAN, self).__init__()
        self.backbone = YOLOv5Backbone()
        self.neck = YOLOv5Neck()
        self.psa = PSA(channels=512)
        self.fusion = FeatureFusion()
        self.classifier = PSAN(num_classes)

    def forward(self, x):
        # Implement full model forward pass
        # ...
        return output
\end{lstlisting}

\subsection{5. Prepare the datasets}
\begin{lstlisting}[language=Python, caption=Dataset Preparation]
class PlantDiseaseDataset(torch.utils.data.Dataset):
    def __init__(self, data_dir, transform=None):
        # Load and preprocess dataset
        # ...

    def __getitem__(self, index):
        # Return a single sample
        # ...

    def __len__(self):
        # Return the size of the dataset
        # ...

# Split dataset
train_dataset, val_dataset, test_dataset = split_dataset(dataset)
\end{lstlisting}

\subsection{6. Train the model}
\begin{lstlisting}[language=Python, caption=Model Training]
def train_model(model, train_loader, val_loader, num_epochs):
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

    for epoch in range(num_epochs):
        model.train()
        for inputs, labels in train_loader:
            # Training loop
            # ...

        model.eval()
        with torch.no_grad():
            for inputs, labels in val_loader:
                # Validation loop
                # ...

        # Print epoch results
        # ...
\end{lstlisting}

\subsection{7. Evaluate the model}
\begin{lstlisting}[language=Python, caption=Model Evaluation]
def evaluate_model(model, test_loader):
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for inputs, labels in test_loader:
            # Evaluation loop
            # ...

    # Calculate accuracy and F1-score
    accuracy = calculate_accuracy(all_preds, all_labels)
    f1_score = calculate_f1_score(all_preds, all_labels)

    return accuracy, f1_score
\end{lstlisting}

\subsection{8. Implement visualization and interpretability}
\begin{lstlisting}[language=Python, caption=Visualization and Interpretability]
from sklearn.manifold import TSNE
import shap

def visualize_tsne(features, labels):
    # Implement t-SNE visualization
    # ...

def interpret_shap(model, inputs):
    # Implement SHAP interpretability
    # ...
\end{lstlisting}

\section{Results and Discussion}
Not DONE YET
% Add your results and discussion here

\section{Conclusion}
The DFN-PSAN architecture, through its enhancements and mathematical formulations, achieves superior plant disease detection by integrating advanced feature extraction, attention mechanisms, and effective classification methods. The implementation approach outlined in this paper provides a structured way to realize this architecture, from understanding the components to evaluating and interpreting the model's performance.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{placeholder_results.png}
\caption{Comparison of DFN-PSAN performance with other models}
\label{fig:results_comparison}
\end{figure}

% Add references section if needed

\end{document}