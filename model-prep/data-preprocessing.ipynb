{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ayush\\apython\\envs\\gpu\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "INPUT_DIR = r\"C:\\Users\\Ayush\\OneDrive\\Documents\\ml\\krishi.ai\\ml\\data\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\Ayush\\OneDrive\\Documents\\ml\\krishi.ai\\ml\\output_data\"\n",
    "IMG_SIZE = 256\n",
    "AUGMENTATION_PROBABILITY = 0.6\n",
    "NUM_WORKERS = multiprocessing.cpu_count()  \n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def basic_preprocessing(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    image = cv2.fastNlMeansDenoisingColored(image, None, 3, 3, 7, 21)\n",
    "    image = cv2.convertScaleAbs(image, alpha=1.0, beta=0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weather augmentation pipeline\n",
    "weather_aug = A.Compose([\n",
    "    A.RandomSunFlare(flare_roi=(0.9, 0, 1, 0.5), angle_lower=0.3, p=AUGMENTATION_PROBABILITY),\n",
    "    A.RandomSunFlare(flare_roi=(0.0, 0.0, 1.0, 0.1), angle_lower=0.3, p=AUGMENTATION_PROBABILITY),\n",
    "    A.RandomRain(drop_length=1.0, drop_width=1, drop_color=(200, 200, 200), blur_value=3, brightness_coefficient=0.6, p=AUGMENTATION_PROBABILITY),\n",
    "    A.RandomShadow(num_shadows_lower=1, num_shadows_upper=5, shadow_dimension=6, shadow_roi=(0, 0.5, 1, 1), p=AUGMENTATION_PROBABILITY),\n",
    "    A.RandomFog(fog_coef_lower=0.25, fog_coef_upper=0.8, alpha_coef=0.3, p=AUGMENTATION_PROBABILITY)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(args):\n",
    "    img_path, output_class_dir, num_augmentations = args\n",
    "    image = cv2.imread(img_path)\n",
    "    \n",
    "    processed_image = basic_preprocessing(image)\n",
    "    \n",
    "    img_name = os.path.basename(img_path)\n",
    "    cv2.imwrite(os.path.join(output_class_dir, f\"proc_{img_name}\"), cv2.cvtColor(processed_image, cv2.COLOR_RGB2BGR))\n",
    "    for i in range(num_augmentations):\n",
    "        augmented = weather_aug(image=processed_image)\n",
    "        aug_image = augmented['image']\n",
    "        cv2.imwrite(os.path.join(output_class_dir, f\"aug_{i}_{img_name}\"), cv2.cvtColor(aug_image, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset_name, num_augmentations):\n",
    "    dataset_dir = os.path.join(INPUT_DIR, dataset_name)\n",
    "    output_dataset_dir = os.path.join(OUTPUT_DIR, dataset_name)\n",
    "    os.makedirs(output_dataset_dir, exist_ok=True)\n",
    "    \n",
    "    all_images = []\n",
    "    \n",
    "    for class_name in os.listdir(dataset_dir):\n",
    "        class_dir = os.path.join(dataset_dir, class_name)\n",
    "        output_class_dir = os.path.join(output_dataset_dir, class_name)\n",
    "        os.makedirs(output_class_dir, exist_ok=True)\n",
    "        \n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            all_images.append((img_path, output_class_dir, num_augmentations))\n",
    "    \n",
    "    # Shuffle the images to distribute workload evenly\n",
    "    random.shuffle(all_images)\n",
    "    \n",
    "    # Process images in parallel\n",
    "    with multiprocessing.Pool(NUM_WORKERS) as pool:\n",
    "        list(tqdm(pool.imap(process_image, all_images), total=len(all_images), desc=f\"Processing {dataset_name}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset_name, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
    "    dataset_dir = os.path.join(OUTPUT_DIR, dataset_name)\n",
    "    train_dir = os.path.join(OUTPUT_DIR, f\"{dataset_name}_train\")\n",
    "    val_dir = os.path.join(OUTPUT_DIR, f\"{dataset_name}_val\")\n",
    "    test_dir = os.path.join(OUTPUT_DIR, f\"{dataset_name}_test\")\n",
    "    \n",
    "    for dir in [train_dir, val_dir, test_dir]:\n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "    \n",
    "    all_images = []\n",
    "    for class_name in os.listdir(dataset_dir):\n",
    "        class_dir = os.path.join(dataset_dir, class_name)\n",
    "        images = os.listdir(class_dir)\n",
    "        all_images.extend([(os.path.join(class_dir, img), class_name) for img in images])\n",
    "    \n",
    "    # Split the data\n",
    "    train_val, test = train_test_split(all_images, test_size=test_ratio, random_state=42)\n",
    "    train, val = train_test_split(train_val, test_size=val_ratio/(train_ratio+val_ratio), random_state=42)\n",
    "    \n",
    "    # Move images to respective directories\n",
    "    for subset, subset_images in [(\"train\", train), (\"val\", val), (\"test\", test)]:\n",
    "        for img_path, class_name in tqdm(subset_images, desc=f\"Moving {subset} images\"):\n",
    "            subset_dir = os.path.join(eval(f\"{subset}_dir\"), class_name)\n",
    "            os.makedirs(subset_dir, exist_ok=True)\n",
    "            img_name = os.path.basename(img_path)\n",
    "            os.rename(img_path, os.path.join(subset_dir, img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Ayush\\\\OneDrive\\\\Documents\\\\ml\\\\krishi.ai\\\\ml\\\\data\\\\test'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mprocess_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m, in \u001b[0;36mprocess_dataset\u001b[1;34m(dataset_name, num_augmentations)\u001b[0m\n\u001b[0;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(output_dataset_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m all_images \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      9\u001b[0m     class_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dataset_dir, class_name)\n\u001b[0;32m     10\u001b[0m     output_class_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dataset_dir, class_name)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Ayush\\\\OneDrive\\\\Documents\\\\ml\\\\krishi.ai\\\\ml\\\\data\\\\test'"
     ]
    }
   ],
   "source": [
    "process_dataset(\"test\", 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process datasets\n",
    "process_dataset(\"Katra-Twelve\", 2)\n",
    "process_dataset(\"BARI-Sunflower\", 2)\n",
    "process_dataset(\"FGVC8\", 6)\n",
    "\n",
    "\n",
    "\n",
    "# Split datasets\n",
    "split_dataset(\"Katra-Twelve\")\n",
    "split_dataset(\"BARI-Sunflower\")\n",
    "split_dataset(\"FGVC8\")\n",
    "\n",
    "print(\"Data preprocessing and splitting completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
